Epoch,Train Loss,Val Loss
2,0.0457,0.0262
3,0.0261,0.0261
4,0.0261,0.0261
5,0.0261,0.0261
6,0.0261,0.0261
7,0.0260,0.0260
8,0.0260,0.0260
9,0.0260,0.0260
10,0.0260,0.0260
11,0.0260,0.0260
12,0.0260,0.0260
13,0.0260,0.0260
14,0.0260,0.0260
15,0.0260,0.0260
Epoch,Train Loss,Val Loss Layers: 30, 64, 128, 128, 64, 32, 5, gamma: 0.1, milestones: 5, 10, 25
1,0.029488,0.026129
2,0.026172,0.026483
3,0.026121,0.026195
4,0.026106,0.026042
5,0.026085,0.026093
6,0.025991,0.025976
7,0.025992,0.025981
8,0.025995,0.025974
9,0.025996,0.025977
10,0.025997,0.025973
11,0.025980,0.025963
12,0.025982,0.025963
13,0.025980,0.025964
14,0.025980,0.025965
15,0.025981,0.025966
16,0.025980,0.025964
17,0.025980,0.025966
18,0.025980,0.025964
19,0.025981,0.025964
20,0.025981,0.025966
21,0.025980,0.025963
22,0.025980,0.025963
23,0.025983,0.025965
Epoch,Train Loss,Val Loss
1,0.029488,0.026129
2,0.026172,0.026483
3,0.026121,0.026195
4,0.026106,0.026042
5,0.026085,0.026093
6,0.025991,0.025976
7,0.025992,0.025981
8,0.025995,0.025974
9,0.025996,0.025977
10,0.025997,0.025973
11,0.025980,0.025963
12,0.025982,0.025963
13,0.025980,0.025964
14,0.025980,0.025965
15,0.025981,0.025966
16,0.025980,0.025964
17,0.025980,0.025966
18,0.025980,0.025964
19,0.025981,0.025964
20,0.025981,0.025966
21,0.025980,0.025963
22,0.025980,0.025963
23,0.025983,0.025965
24,0.025982,0.025964
25,0.025981,0.025964
26,0.025980,0.025962
27,0.025977,0.025962
