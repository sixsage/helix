{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sixsa\\anaconda3\\envs\\helix\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "# LEARNING_RATE = 0.001\n",
    "EPOCH = 50\n",
    "\n",
    "# RESULTS_PATH = 'autoencoder_points\\\\results2\\\\'\n",
    "# DATASET_PATH = 'tracks_100k_updated.txt'\n",
    "# ENCODER_PATH = 'autoencoder_points\\\\results_trig7_minmax\\\\encoder_epoch_50.pth'\n",
    "# DECODER_PATH = 'autoencoder_points\\\\results_trig7_minmax\\\\decoder_epoch_50.pth'\n",
    "\n",
    "# ENCODER_PATH = 'asymmetric\\\\results3_higher_trig_minmax\\\\encoder_epoch_50.pth'\n",
    "# DECODER_PATH = 'asymmetric\\\\results3_higher_trig_minmax\\\\decoder_epoch_50.pth'\n",
    "# HELIX_PATH = 'tracks_100k_updated_asymmetric_higher_test.txt'\n",
    "# NON_HELIX_PATH = 'sintracks_100k_updated_asymmetric_higher_test.txt'\n",
    "\n",
    "# ENCODER_PATH = 'not_gaussian\\\\results6_trig_wider_minmax\\\\encoder_epoch_100.pth'\n",
    "# DECODER_PATH = 'not_gaussian\\\\results6_trig_wider_minmax\\\\decoder_epoch_100.pth'\n",
    "# HELIX_PATH = 'tracks_100k_updated_non_gaussian_wider_test.txt'\n",
    "# NON_HELIX_PATH = 'sintracks_100k_updated_non_gaussian_wider_test.txt'\n",
    "\n",
    "ENCODER_PATH = 'autoencoder_points\\\\results_trig11_minmax\\\\encoder_epoch_100.pth'\n",
    "DECODER_PATH = 'autoencoder_points\\\\results_trig11_minmax\\\\decoder_epoch_100.pth'\n",
    "HELIX_PATH = 'tracks_100k_updated_test.txt'\n",
    "NON_HELIX_PATH = 'sintracks_100k_updated_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        with open(path, 'r') as file:\n",
    "            content = file.read()\n",
    "            data_points = content.split('EOT')\n",
    "\n",
    "            data_points = [dp.strip() for dp in data_points if dp.strip()]\n",
    "            data_points = [dp.split('\\n') for dp in data_points]\n",
    "            data_points = [[[float(cell) for cell in row.split(', ')] for row in dp] for dp in data_points]\n",
    "            self.original_targets = np.array([dp[0] for dp in data_points])\n",
    "            input_points = [dp[1:] for dp in data_points]\n",
    "            targets_2 = np.delete(self.original_targets, 1, 1)\n",
    "            targets_2 = np.hstack((targets_2, np.cos(self.original_targets[:, 1])[..., None]))\n",
    "            targets_cos_sin = np.hstack((targets_2, np.sin(self.original_targets[:, 1])[..., None]))\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.rescaled_targets = self.scaler.fit_transform(targets_cos_sin)\n",
    "            self.rescaled_targets = torch.tensor(self.rescaled_targets)\n",
    "            self.original_targets = torch.tensor(targets_cos_sin)\n",
    "            inputs = []\n",
    "            for input in input_points:\n",
    "                combined = []\n",
    "                for coordinate in input:\n",
    "                    combined += coordinate\n",
    "                inputs.append(combined)\n",
    "            self.inputs = torch.tensor(np.array(inputs))\n",
    "            # self.inputs = torch.tensor(np.array(input_points))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rescaled_targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = self.rescaled_targets[idx]\n",
    "        input = self.inputs[idx]\n",
    "        return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.layer1 = nn.Linear(30, 32)\n",
    "        # self.layer2 = nn.Linear(32, 64)\n",
    "        # self.layer3 = nn.Linear(64, 5)\n",
    "        self.layer1 = nn.Linear(30, 200)\n",
    "        self.layer2 = nn.Linear(200, 400)\n",
    "        self.layer3 = nn.Linear(400, 800)\n",
    "        self.layer4 = nn.Linear(800, 800)\n",
    "        self.layer5 = nn.Linear(800, 800)\n",
    "        self.layer6 = nn.Linear(800, 400)\n",
    "        self.layer7 = nn.Linear(400, 200)\n",
    "        self.output_layer = nn.Linear(200, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.layer1(x))\n",
    "        x = F.leaky_relu(self.layer2(x))\n",
    "        x = F.leaky_relu(self.layer3(x))\n",
    "        x = F.leaky_relu(self.layer4(x))\n",
    "        x = F.leaky_relu(self.layer5(x))\n",
    "        x = F.leaky_relu(self.layer6(x))\n",
    "        x = F.leaky_relu(self.layer7(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.layer1 = nn.Linear(5, 64)\n",
    "        # self.layer2 = nn.Linear(64, 32)\n",
    "        # self.layer3 = nn.Linear(32, 30)\n",
    "        self.layer1 = nn.Linear(6, 200)\n",
    "        self.layer2 = nn.Linear(200, 200)\n",
    "        self.layer3 = nn.Linear(200, 200)\n",
    "        self.layer4 = nn.Linear(200, 400)\n",
    "        self.layer5 = nn.Linear(400, 800)\n",
    "        self.layer6 = nn.Linear(800, 800)\n",
    "        self.layer7 = nn.Linear(800, 800)\n",
    "        self.layer8 = nn.Linear(800, 400)\n",
    "        self.layer9 = nn.Linear(400, 200)\n",
    "        self.output_layer = nn.Linear(200, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = F.relu(self.layer6(x))\n",
    "        x = F.relu(self.layer7(x))\n",
    "        x = F.relu(self.layer8(x))\n",
    "        x = F.relu(self.layer9(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i need the original parameters, original input points, decoder output, encoder output, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(encoder, decoder, encoder_optimizer, decoder_optimizer, encoder_scheduler, decoder_scheduler, val_dl, device, prev_encoder_path, prev_decoder_path, data_size):\n",
    "    print(f\"Loading model from {prev_encoder_path}\")\n",
    "    checkpoint = torch.load(prev_encoder_path)\n",
    "    encoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "    encoder_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    print(f\"Loading model from {prev_decoder_path}\")\n",
    "    checkpoint = torch.load(prev_decoder_path)\n",
    "    decoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "    decoder_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        decoder_outputs = torch.zeros(data_size, 10, 3)\n",
    "        encoder_outputs = torch.zeros(data_size, 6)\n",
    "        distances = torch.zeros(data_size)\n",
    "        current_size = 0\n",
    "        for input, target in val_dl:\n",
    "            input = input.float().to(device)\n",
    "            target = target.float().to(device)\n",
    "            encoder_output = encoder(input)\n",
    "            decoder_output = decoder(encoder_output)\n",
    "            first_dim = torch.numel(decoder_output)  // 30\n",
    "            decoder_output = decoder_output.reshape(first_dim, 10, 3)\n",
    "            reshaped_points = input.reshape(first_dim, 10, 3)\n",
    "            squared_diff = (decoder_output - reshaped_points) ** 2\n",
    "            pairwise_distances = torch.sqrt(squared_diff.sum(dim=-1))\n",
    "            distance = pairwise_distances.sum(dim=-1)\n",
    "            # distance = torch.norm(decoder_output - reshaped_points, 2, dim=(1, 2))\n",
    "            # distance = torch.sum(torch.square(output_points - reshaped_points), dim=(1, 2))\n",
    "            distances[current_size:current_size + distance.shape[0]] = distance\n",
    "            encoder_outputs[current_size:current_size + distance.shape[0], :] = encoder_output\n",
    "            decoder_outputs[current_size:current_size + target.shape[0], :, :] = decoder_output\n",
    "            current_size += distance.shape[0]\n",
    "    \n",
    "    print(encoder_output)\n",
    "    print(decoder_output)\n",
    "        \n",
    "    return encoder_outputs, decoder_outputs, distances\n",
    "\n",
    "    # print(distances[-1])\n",
    "    # print(distances)\n",
    "    # print(distances.shape)\n",
    "    # print(torch.mean(distances))\n",
    "    # print(\"predictions:\", predictions)\n",
    "    # print(\"targets:\", targets)\n",
    "    # print(\"predicted helix but was actually non-helix\")\n",
    "    # predict_helix = predictions == 1\n",
    "    # wrong = predictions != targets\n",
    "    # mask = torch.logical_and(predict_helix, wrong)\n",
    "    # print(predictions[mask].size())\n",
    "    # print(\"predicted non-helix but was helix\")\n",
    "    # predict_non_helix = predictions == 0\n",
    "    # wrong = predictions != targets\n",
    "    # mask = torch.logical_and(predict_non_helix, wrong)\n",
    "    # print(predictions[mask].size())\n",
    "    # print((predictions == targets).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    dataset = Dataset(HELIX_PATH)\n",
    "    train_size = int(TRAIN_RATIO * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    encoder = Encoder()\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = Decoder()\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "    encoder_criterion = nn.MSELoss()\n",
    "    decoder_criterion = nn.MSELoss()\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr = LEARNING_RATE)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr = LEARNING_RATE)\n",
    "    encoder_scheduler = torch.optim.lr_scheduler.MultiStepLR(encoder_optimizer, milestones=[15, 30, 50], gamma=0.5)\n",
    "    decoder_scheduler = torch.optim.lr_scheduler.MultiStepLR(decoder_optimizer, milestones=[15, 30, 50], gamma=0.1)\n",
    "    \n",
    "    parameter_prediction, point_prediction, distances = calc_distance(encoder, decoder, encoder_optimizer, decoder_optimizer, encoder_scheduler, decoder_scheduler, val_dl=dataloader, device=device, \n",
    "                  prev_encoder_path=ENCODER_PATH, prev_decoder_path=DECODER_PATH, data_size=len(dataset))\n",
    "\n",
    "    return parameter_prediction, point_prediction, distances, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model from autoencoder_points\\results_trig11_minmax\\encoder_epoch_100.pth\n",
      "Loading model from autoencoder_points\\results_trig11_minmax\\decoder_epoch_100.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsa\\AppData\\Local\\Temp\\ipykernel_29748\\537365674.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(prev_encoder_path)\n",
      "C:\\Users\\sixsa\\AppData\\Local\\Temp\\ipykernel_29748\\537365674.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(prev_decoder_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1562, 0.8674, 0.7232, 0.3198, 0.2274, 0.0873],\n",
      "        [0.1843, 0.1802, 0.6955, 0.3860, 0.6081, 0.0101],\n",
      "        [0.1337, 0.0014, 0.4317, 0.4273, 0.0936, 0.2139],\n",
      "        ...,\n",
      "        [0.1477, 0.6103, 0.7657, 0.6165, 0.2624, 0.9399],\n",
      "        [0.1193, 0.4361, 0.6622, 0.4739, 0.4886, 0.9950],\n",
      "        [0.1354, 0.5501, 0.6650, 0.7514, 0.8078, 0.0999]], device='cuda:0')\n",
      "tensor([[[-0.8433,  0.5422,  2.5505],\n",
      "         [-1.6790,  1.0721,  3.1652],\n",
      "         [-2.5256,  1.6279,  3.8207],\n",
      "         ...,\n",
      "         [-6.8501,  4.1225,  6.9808],\n",
      "         [-7.7493,  4.5861,  7.6217],\n",
      "         [-8.6372,  5.0545,  8.2406]],\n",
      "\n",
      "        [[-0.9739, -0.2450,  2.1410],\n",
      "         [-1.9443, -0.4976,  2.5664],\n",
      "         [-2.8940, -0.8001,  2.9771],\n",
      "         ...,\n",
      "         [-7.5032, -2.7732,  5.0851],\n",
      "         [-8.3711, -3.2612,  5.5082],\n",
      "         [-9.2427, -3.7846,  5.9358]],\n",
      "\n",
      "        [[-0.6327,  0.7724, -0.4410],\n",
      "         [-1.3078,  1.5102, -0.1334],\n",
      "         [-2.0445,  2.1938,  0.1613],\n",
      "         ...,\n",
      "         [-6.4820,  4.6759,  1.7036],\n",
      "         [-7.5213,  4.9742,  2.0262],\n",
      "         [-8.5672,  5.1947,  2.3340]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8619,  0.4858,  2.1223],\n",
      "         [ 1.7405,  0.9661,  1.8791],\n",
      "         [ 2.6233,  1.4760,  1.6282],\n",
      "         ...,\n",
      "         [ 6.8253,  4.2082,  0.3723],\n",
      "         [ 7.6287,  4.7795,  0.1292],\n",
      "         [ 8.4340,  5.3743, -0.1203]],\n",
      "\n",
      "        [[ 0.9902,  0.0353,  1.6268],\n",
      "         [ 1.9909,  0.0825,  1.7857],\n",
      "         [ 2.9925,  0.1495,  1.9529],\n",
      "         ...,\n",
      "         [ 7.9523,  0.7665,  2.7646],\n",
      "         [ 8.9359,  0.9460,  2.9299],\n",
      "         [ 9.9157,  1.1556,  3.0935]],\n",
      "\n",
      "        [[-0.7863, -0.6324,  0.8245],\n",
      "         [-1.5658, -1.2743,  0.1822],\n",
      "         [-2.3450, -1.9193, -0.4611],\n",
      "         ...,\n",
      "         [-6.0330, -5.3339, -3.6727],\n",
      "         [-6.7235, -6.0684, -4.3078],\n",
      "         [-7.4147, -6.7875, -4.9535]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "parameters_prediction, points_prediction, distances, dataset = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1082, 0.4114, 0.5001, 0.5248, 0.1176, 0.8224],\n",
       "        [0.1867, 0.8856, 0.4980, 0.4746, 0.0081, 0.5974],\n",
       "        [0.1173, 0.3245, 0.4128, 0.5919, 0.6547, 0.9682],\n",
       "        ...,\n",
       "        [0.1477, 0.6103, 0.7657, 0.6165, 0.2624, 0.9399],\n",
       "        [0.1193, 0.4361, 0.6622, 0.4739, 0.4886, 0.9950],\n",
       "        [0.1354, 0.5501, 0.6650, 0.7514, 0.8078, 0.0999]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2627, 0.3125, 0.7820,  ..., 0.5238, 0.5991, 0.5923],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.2627, 0.3125, 0.7820,  ..., 0.5238, 0.5991, 0.5923])\n"
     ]
    }
   ],
   "source": [
    "original_inputs = dataset.inputs.reshape(points_prediction.shape[0], 10, 3)\n",
    "# print(torch.sqrt(torch.sum(torch.square(points_prediction - original_inputs), dim=(1, 2))))\n",
    "squared_diff = (points_prediction - original_inputs) ** 2\n",
    "pairwise_distances = torch.sqrt(squared_diff.sum(dim=-1))\n",
    "print(pairwise_distances.sum(dim=-1))\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_difference(prediction, actual):\n",
    "    return torch.abs(actual - prediction)\n",
    "\n",
    "def change_trig_to_angle(input):\n",
    "    cos_values = input[:, 4]\n",
    "    sin_values = input[:, 5]\n",
    "    pred_angle = torch.atan2(sin_values, cos_values)\n",
    "    pred_angle= torch.remainder(pred_angle, np.pi).reshape(input.shape[0], 1)\n",
    "    return torch.hstack((input[:, 0:1], pred_angle, input[:, 1:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_prediction = dataset.scaler.inverse_transform(parameters_prediction)\n",
    "parameters_prediction = torch.tensor(parameters_prediction)\n",
    "parameters_prediction = change_trig_to_angle(parameters_prediction)\n",
    "original_parameters_with_angle = change_trig_to_angle(dataset.original_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_parameters_with_angle, original_inputs\n",
    "# inputs_prediction, parameters_prediction, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.1405,  0.4858,  2.2962,  3.2411,  3.6806]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "result_mae = torch.mean(absolute_difference(parameters_prediction, original_parameters_with_angle), dim=0)\n",
    "MIN_PER_COLUMN = torch.min(original_parameters_with_angle, dim=0, keepdim=True)\n",
    "MAX_PER_COLUMN = torch.max(original_parameters_with_angle, dim=0, keepdim=True)\n",
    "RANGE_PER_COLUMN = (MAX_PER_COLUMN.values - MIN_PER_COLUMN.values)\n",
    "RANGE_PER_COLUMN_NUMPY = RANGE_PER_COLUMN.numpy()\n",
    "print(torch.div(result_mae, RANGE_PER_COLUMN) * 100)\n",
    "\n",
    "def calculate_parameter_error(original, prediction):\n",
    "    original = np.array(original)\n",
    "    prediction = np.array(prediction)\n",
    "    error = np.abs(original - prediction)\n",
    "    return error / RANGE_PER_COLUMN_NUMPY * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3000e-02, 3.1400e+00, 1.7499e+02, 8.8600e+00, 2.7000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANGE_PER_COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_distances = distances.tolist()\n",
    "list_original_parameters_with_angle = original_parameters_with_angle.tolist()\n",
    "list_original_inputs = original_inputs.tolist()\n",
    "list_parameters_prediction = parameters_prediction.tolist()\n",
    "list_points_prediction = points_prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = zip(list_distances, list_original_parameters_with_angle, list_original_inputs, list_parameters_prediction, list_points_prediction)\n",
    "sorted_combined = sorted(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_r0=1.0\n",
    "max_r0=10.0\n",
    "nlayers=10\n",
    "sigma=0.01\n",
    "\n",
    "def track(phi, d0,phi0,pt,dz,tanl):\n",
    "    alpha = 1/2 # 1/cB\n",
    "    q=1\n",
    "    kappa = q/pt\n",
    "    rho = alpha/kappa\n",
    "    x = d0*np.cos(phi0) + rho*(np.cos(phi0)-np.cos(phi0+phi))\n",
    "    y = d0*np.sin(phi0) + rho*(np.sin(phi0)-np.sin(phi0+phi))\n",
    "    z = dz - rho*tanl*phi\n",
    "    return x,y,z\n",
    "\n",
    "def dr(phi, r02,d0,phi0,pt,dz,tanl):\n",
    "\n",
    "    # get the xyz of the track at this phi\n",
    "    x,y,z = track(phi, d0,phi0,pt,dz,tanl)\n",
    "    r2=x*x+y*y\n",
    "\n",
    "    # get the distance from the target r02\n",
    "    dr = np.fabs(r2-r02)\n",
    "\n",
    "    return dr\n",
    "\n",
    "def find_phi(r0, d0,phi0,pt,dz,tanl):\n",
    "\n",
    "    # this is lazy, but rather than inverting the equations we just minimize the distance\n",
    "    res = scipy.optimize.minimize(dr,0,method='Nelder-Mead',args = (r0, d0,phi0,pt,dz,tanl))#, bounds =(0,1.0))\n",
    "\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "# find the intersections with the detector layers for these track parameters, add noise\n",
    "def make_hits(params):\n",
    "    xs=[]\n",
    "    ys=[]\n",
    "    zs =[]\n",
    "    \n",
    "    for r0 in np.linspace(min_r0,max_r0,nlayers):\n",
    "        phi0 = find_phi(r0*r0,*params)\n",
    "        x0,y0,z0 = track(phi0,*params)\n",
    "        xs.append(x0)\n",
    "        ys.append(y0)\n",
    "        zs.append(z0)\n",
    "\n",
    "\n",
    "    return xs,ys,zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateXYZ(combined):\n",
    "    x = [x for x, y, z in combined]\n",
    "    y = [y for x, y, z in combined]\n",
    "    z = [z for x, y, z in combined]\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def plotTracks(combined):\n",
    "    distances, original_targets, original_points, predicted_targets, predicted_points = combined\n",
    "    original_x, original_y, original_z = make_hits(original_targets)\n",
    "    pred_x, pred_y, pred_z = make_hits(predicted_targets)\n",
    "\n",
    "    figure, axis = plt.subplots(1, 2)\n",
    "    axis[0].plot(original_x,original_y,\".\",color='green')\n",
    "    axis[0].plot(pred_x,pred_y,\"x\",color='red')\n",
    "    axis[0].legend([\"original xy\", \"predicted_xy\"])\n",
    "    axis[0].set_xlim(-10, 10)\n",
    "    axis[0].set_ylim(-10, 10)\n",
    "\n",
    "    axis[1].plot(original_x,original_z,\".\",color='green')\n",
    "    axis[1].plot(pred_x,pred_z,\"x\",color='red')\n",
    "    axis[1].legend([\"original xz\", \"predicted_xz\"])\n",
    "    axis[1].set_xlim(-10, 10)\n",
    "    axis[1].set_ylim(-10, 10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotPoints(combined):\n",
    "    distances, original_targets, original_points, predicted_targets, predicted_points = combined\n",
    "    original_x, original_y, original_z = separateXYZ(original_points)\n",
    "    pred_x, pred_y, pred_z = separateXYZ(predicted_points)\n",
    "\n",
    "    original_param_x, original_param_y, original_param_z = make_hits(original_targets)\n",
    "    pred_param_x, pred_param_y, pred_param_z = make_hits(predicted_targets)\n",
    "\n",
    "    print(\"original:\", original_targets)\n",
    "    print(\"predicted:\", predicted_targets)\n",
    "    print(\"error:\", calculate_parameter_error(original_targets, predicted_targets))\n",
    "    print(\"distance:\", distances)\n",
    "\n",
    "    figure, axis = plt.subplots(1, 2)\n",
    "    axis[0].plot(original_x,original_y,\".\",color='green')\n",
    "    axis[0].plot(pred_x,pred_y,\".\",color='red')\n",
    "    # axis[0].plot(original_param_x,original_param_y,\"x\",color='blue')\n",
    "    # axis[0].plot(pred_param_x,pred_param_y,\"x\",color='orange')\n",
    "    axis[0].legend([\"original xy\", \"predicted_xy\"])\n",
    "    axis[0].set_xlim(-10, 10)\n",
    "    axis[0].set_ylim(-10, 10)\n",
    "\n",
    "    axis[1].plot(original_x,original_z,\".\",color='green')\n",
    "    axis[1].plot(pred_x,pred_z,\".\",color='red')\n",
    "    # axis[1].plot(original_param_x,original_param_z,\"x\",color='blue')\n",
    "    # axis[1].plot(pred_param_x,pred_param_z,\"x\",color='orange')\n",
    "    axis[1].legend([\"original xz\", \"predicted_xz\"])\n",
    "    axis[1].set_xlim(-10, 10)\n",
    "    axis[1].set_ylim(-10, 10)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [0.0172, 1.79, 26.75, -1.34, -0.5]\n",
      "predicted: [0.00695763366818428, 1.791751239865125, 27.642990236617624, -1.056162536740303, -0.3338454744219782]\n",
      "error: [[20.04376973  0.05577197  0.5103093   3.22176462  6.04198275]]\n",
      "distance: 3.7627792358398438\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGiCAYAAAAP/nkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABAKElEQVR4nO3deXxU9b3/8fckkLBOYiCQpAkBJAqo7LJdl1S5RgQtLQ8vxQXQIGgBF6gFVAT0ekHFpS5VuI2JPtyo/SltuYpVjCsIlMWqQEwwIUSToCAzsiUk8/39ERkZspCQyZyZOa/n43EePubMOWc+p2Q+fc9ZvsdhjDECAACwkQirCwAAAAg0AhAAALAdAhAAALAdAhAAALAdAhAAALAdAhAAALAdAhAAALAdAhAAALAdAhAAALAdAhAAALCdFg1AH374oa688kolJSXJ4XBo1apVPu8bY3TvvfcqMTFRbdu21ahRo5Sfn3/K7T799NPq3r272rRpo2HDhmnjxo0ttAcArEDvANDSWjQAHTp0SP3799fTTz9d5/sPPfSQnnjiCT377LPasGGD2rdvr4yMDB09erTeba5cuVKzZ8/WwoULtWXLFvXv318ZGRnau3dvS+0GgACjdwBocSZAJJk33njD+9rj8ZiEhATz8MMPe+cdOHDAREdHm1deeaXe7QwdOtTMmDHD+7q6utokJSWZJUuWtEjdAKxF7wDQElpZFbwKCwtVVlamUaNGeefFxMRo2LBhWr9+vX7729/WWqeyslKbN2/W/PnzvfMiIiI0atQorV+/vt7PqqioUEVFhfe1x+PR/v371alTJzkcDj/tEYCmMMboxx9/VFJSkiIiGn8wmt4B2Nfp9o26WBaAysrKJEldu3b1md+1a1fveyf7/vvvVV1dXec6O3furPezlixZosWLFzezYgAtYc+ePUpOTm708vQOAE3tG3WxLAAF0vz58zV79mzva5fLpW7dumnPnj1yOp0WVgbYl9vtVkpKijp27Gh1KfWidwDBxZ99w7IAlJCQIEkqLy9XYmKid355ebkGDBhQ5zqdO3dWZGSkysvLfeaXl5d7t1eX6OhoRUdH15rvdDppYoDFmnoqid4BwB+noC0bB6hHjx5KSEjQ2rVrvfPcbrc2bNigESNG1LlOVFSUBg8e7LOOx+PR2rVr610HQHihdwDwhxY9AnTw4EEVFBR4XxcWFmrbtm2Ki4tTt27ddPvtt+u///u/lZaWph49emjBggVKSkrSuHHjvOtceuml+vWvf62ZM2dKkmbPnq3JkydryJAhGjp0qB5//HEdOnRIN9xwQ0vuCoAAoncAaHEteYtZbm6ukVRrmjx5sjGm5nbWBQsWmK5du5ro6Ghz6aWXmry8PJ9tpKammoULF/rMe/LJJ023bt1MVFSUGTp0qPn000+bVJfL5TKSjMvlas7uAWiGhr6H9A4AdfHnd9BhjDFWBC8rud1uxcTEyOVycR7/NBljVFVVperqaqtLQZCKjIxUq1at6j1XH4rfw1CsOdjQO9CQQPYNW9wFBv+qrKxUaWmpDh8+bHUpCHLt2rVTYmKioqKirC4FQYDegcYIVN8gAKFJPB6PCgsLFRkZqaSkJEVFRTEgHGoxxqiyslLfffedCgsLlZaW1uxByxDa6B04lUD3DQIQmqSyslIej0cpKSlq166d1eUgiLVt21atW7fW7t27VVlZqTZt2lhdEixE70BjBLJv8JMMp4Vf82gM/k5wMv4mcCqB+hvhLxEAANgOAQgAANgOAQhowKJFi+p9vEJ90tPTdfvtt1teBwBr0T+CGxdBAw34/e9/r1mzZjVpnddff12tW7duoYoAhAr6R3AjAMEyJe4S5e/LV1qnNCU7k60ux4cxRtXV1erQoYM6dOjQpHXj4uJaqCoAx9E/0FycAoMlsrZkKfXxVF3ywiVKfTxVWVuyWvTzKioqdOutt6pLly5q06aNLrjgAm3atMn7/vvvvy+Hw6G33npLgwcPVnR0tD7++ONah46rqqp06623KjY2Vp06ddLcuXM1efJkn2dQnXwIu3v37vqf//kf3XjjjerYsaO6deumFStW+NQ3d+5cnXXWWWrXrp169uypBQsW6NixY43ev/vuu09JSUnat2+fd96YMWP0y1/+Uh6PRzfeeKPGjh3rs86xY8fUpUsXZWW17P/2gL/RPwLbP3JycuRwOGpNixYtavRnBCMCEAKuxF2iaaunyWM8kiSP8Wj66ukqcZe02Gf+4Q9/0P/7f/9Pzz//vLZs2aJevXopIyND+/fv91lu3rx5Wrp0qXbs2KF+/frV2s6DDz6ol156SdnZ2frkk0/kdru1atWqU37+I488oiFDhmjr1q363e9+p1tuuUV5eXne9zt27KicnBxt375df/zjH/W///u/euyxxxq9f3fffbe6d++uqVOnSpKefvpprVu3Ts8//7wiIiI0depUrVmzRqWlpd51Vq9ercOHD2vChAmN/hzAavSPwPePCRMmqLS01Du98soratWqlf7jP/6j0Z8RlJr9NLEQxAMNT9+RI0fM9u3bzZEjR057G+99/Z7RItWacgtz/VfoCQ4ePGhat25tXnrpJe+8yspKk5SUZB566CFjzM8P31y1apXPugsXLjT9+/f3vu7atat5+OGHva+rqqpMt27dzK9+9SvvvIsvvtjcdttt3tepqanmuuuu8772eDymS5cu5plnnqm35ocfftgMHjy43jrqsmvXLtOxY0czd+5c07ZtW5/9NcaYvn37mgcffND7+sorrzRTpkxpcJvN1dDfSyh+D0Ox5mDhj95hDP3Dqv5xXEFBgYmLi/Pue0sIVN/gGiAEXFqnNEU4Iry/4CQp0hGpXnG9WuTzdu3apWPHjvn8WmndurWGDh2qHTt2+Cw7ZMiQerfjcrlUXl6uoUOHeudFRkZq8ODB8ng89a4nyefXoMPhUEJCgvbu3eudt3LlSj3xxBPatWuXDh48qKqqqiY/6K9nz55atmyZpk+frgkTJuiaa67xeX/q1KlasWKF/vCHP6i8vFxvvfWW3nvvvSZ9BmA1+oc1/eP4PowdO1ZjxozRnXfe2aTtByNOgSHgkp3JWjF2hSIdkZJqmtfyscuD4kLG9u3bt8h2T76rw+FweJve+vXrde211+qKK67Q6tWrtXXrVt19992qrKxs8ud8+OGHioyMVFFRkaqqqnzemzRpkr7++mutX79eL774onr06KELL7zw9HcKsAD9w5r+UV1drQkTJsjpdNa6BilUEYBgicxBmSq6vUi5k3NVdHuRMgdltthnnXnmmYqKitInn3zinXfs2DFt2rRJffv2bfR2YmJi1LVrV5+LH6urq7Vly5Zm1bdu3Tqlpqbq7rvv1pAhQ5SWlqbdu3c3eTsrV67U66+/rvfff1/FxcW6//77fd7v1KmTxo0bp+zsbOXk5OiGG25oVt2AVegfPwtU/7jjjjv0+eefa9WqVWHzXD9OgcEyyc7kgPxqa9++vW655RbdeeediouLU7du3fTQQw/p8OHDysxsWuOcNWuWlixZol69eql379568skn9cMPPzTrqdZpaWkqLi7Wq6++qvPPP1//93//pzfeeKNJ2ygpKdEtt9yiBx98UBdccIGys7M1duxYjR49WsOHD/cuN3XqVI0dO1bV1dWaPHnyadcMWI3+USMQ/SM7O1t/+tOf9MYbb8jhcKisrEySTus2/2DCESDYwtKlSzV+/Hhdf/31GjRokAoKCvT222/rjDPOaNJ25s6dq4kTJ2rSpEkaMWKEOnTooIyMjGb9Irrqqqt0xx13aObMmRowYIDWrVunBQsWNHp9Y4ymTJmioUOHaubMmZKkjIwM3XLLLbruuut08OBB77KjRo1SYmKiMjIylJSUdNo1A3Zi9/7xwQcfqLq6WldddZUSExO907Jly0677mDgMMYYq4sINLfbrZiYGLlcriZfKGZ3R48eVWFhoXr06BE2h0Gbw+PxqE+fPvqv//qvWoeMg9HBgwf1i1/8QtnZ2frNb37T4p/X0N9LKH4PQ7HmYEHvqC3U+kegBKpvcAoMaILdu3frn//8py6++GJVVFToqaeeUmFhYZ13TAQTj8ej77//Xo888ohiY2N11VVXWV0SYDuh2j/CFQEIaIKIiAjl5OTo97//vYwxOvfcc/Xuu++qT58+VpfWoOLiYvXo0UPJycnKyclRq1Z89YFAC9X+Ea7ogkATpKSk+NwNEiq6d+8uG57tBoJKqPaPcMVF0AAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQEAL6N69ux5//HHva4fDoVWrVgW8jkWLFmnAgAEB/1wAp4feETgEICAASktLNXr06EYta4fGA6Bx6B0thwAE65SUSLm5Nf8NQpWVlX7bVkJCgqKjo/22PcD2grh/0DtCAwEI1sjKklJTpUsuqflvVlaLf2R6erpmzpypmTNnKiYmRp07d9aCBQu8IyR3795d999/vyZNmiSn06lp06ZJkj7++GNdeOGFatu2rVJSUnTrrbfq0KFD3u3u3btXV155pdq2basePXropZdeqvXZJx/GLikp0cSJExUXF6f27dtryJAh2rBhg3JycrR48WJ99tlncjgccjgcysnJkSQdOHBAU6dOVXx8vJxOpy655BJ99tlnPp+zdOlSde3aVR07dlRmZqaOHj3aqP9tjh49qnPOOce7z5K0a9cudezYUc8995wOHTokp9Opv/71rz7rrVq1Su3bt9ePP/7YqM8B/CLA/YPeUb9T9Y7j//sdr+nEqaioqFGf0WKMDblcLiPJuFwuq0sJOUeOHDHbt283R44cOf2N7NljTESEMdLPU2RkzfwWdPHFF5sOHTqY2267zezcudO8+OKLpl27dmbFihXGGGNSU1ON0+k0y5YtMwUFBd6pffv25rHHHjNfffWV+eSTT8zAgQPNlClTvNsdPXq06d+/v1m/fr3517/+ZUaOHGnatm1rHnvsMe8ykswbb7xhjDHmxx9/ND179jQXXnih+eijj0x+fr5ZuXKlWbdunTl8+LCZM2eOOeecc0xpaakpLS01hw8fNsYYM2rUKHPllVeaTZs2ma+++srMmTPHdOrUyezbt88YY8zKlStNdHS0+fOf/2x27txp7r77btOxY0fTv3//Rv3vs3XrVhMVFWVWrVplqqqqzPDhw82vf/1r7/s33XSTueKKK3zWueqqq8ykSZPq3WZDfy+h+D0MxZqDhV96hzGW9A96R8NO1Tv27dvnram0tNT85je/MWeffba3vpMFqm8QgNAkfmli773n27yOT7m5fquzLhdffLHp06eP8Xg83nlz5841ffr0McbUNLFx48b5rJOZmWmmTZvmM++jjz4yERER5siRIyYvL89IMhs3bvS+v2PHDiOp3ia2fPly07FjR2/zOdnChQtrNZ6PPvrIOJ1Oc/ToUZ/5Z555plm+fLkxxpgRI0aY3/3udz7vDxs2rNFNzBhjHnroIdO5c2czc+ZMk5iYaL7//nvvexs2bDCRkZHm22+/NcYYU15eblq1amXef//9erdHAMJxfgtAFvQPesepNdQ7TvToo4+a2NhYk5eXV++2AtU3OAWGwEtLkyJO+tOLjJR69Wrxjx4+fLgcDof39YgRI5Sfn6/q6mpJ0pAhQ3yW/+yzz5STk6MOHTp4p4yMDHk8HhUWFmrHjh1q1aqVBg8e7F2nd+/eio2NrbeGbdu2aeDAgYqLi2t03Z999pkOHjyoTp06+dRSWFioXbt2SZJ27NihYcOG+aw3YsSIRn+GJM2ZM0dnnXWWnnrqKT333HPq1KmT972hQ4fqnHPO0fPPPy9JevHFF5WamqqLLrqoSZ8BNItF/YPe0bCGesdxb731lubNm6eVK1fqrLPOatL2WwJPg0fgJSdLK1ZI06dL1dU1zWv58pr5Fmvfvr3P64MHD2r69Om69dZbay3brVs3ffXVV03+jLZt2zZ5nYMHDyoxMVHvv/9+rfcaaphNtXfvXn311VeKjIxUfn6+Lr/8cp/3p06dqqefflrz5s1Tdna2brjhBp//UwBaXJD2D3pHw71j+/bt+u1vf6ulS5fqsssu89vnNoflR4C6d+9e58VRM2bMqHP5nJycWsu2adMmwFWj2TIzpaKimrs4iopqXgfAhg0bfF5/+umnSktLU2RkZJ3LDxo0SNu3b1evXr1qTVFRUerdu7eqqqq0efNm7zp5eXk6cOBAvTX069dP27Zt0/79++t8Pyoqyvur8sQ6ysrK1KpVq1p1dO7cWZLUp0+fOvevKW688Uadd955ev755zV37lzt2LHD5/3rrrtOu3fv1hNPPKHt27dr8uTJTdq+v9A3bM6C/kHvaFhDveP777/XlVdeqfHjx+uOO+5o0nZbVLNPojXT3r17fS6Oeuedd4wkk1vP+dzs7GzjdDp91ikrK2vSZ3Ie//T57Ty+BY5fyHjHHXeYnTt3mpdfftm0b9/ePPvss8aYmvP4J557N8aYzz77zLRt29bMmDHDbN261Xz11Vdm1apVZsaMGd5lLr/8cjNw4EDz6aefmn/961/mggsuaPBCxoqKCnPWWWeZCy+80Hz88cdm165d5q9//atZt26dMcaYl156ybRv395s3brVfPfdd+bo0aPG4/GYCy64wPTv39+8/fbbprCw0HzyySfmrrvuMps2bTLGGPPqq6+aNm3amOeee87k5eWZe++9t0kXMj711FMmNjbWFBcXG2OMmThxohk4cKCpqKjwWe6aa64xUVFR5vLLLz/lNlvqXL4VfaO5NdsdvcO+veOiiy4y5557rtm9e7fPd7CqqqrO7dn2IujbbrvNnHnmmT4Xm50oOzvbxMTENOszaGKnL9Sb2O9+9ztz8803G6fTac444wxz1113ef/W6mpixhizceNG85//+Z+mQ4cOpn379qZfv37mgQce8L5fWlpqxowZY6Kjo023bt3MCy+8UGtbJzYxY4wpKioy48ePN06n07Rr184MGTLEbNiwwRhjzNGjR8348eNNbGyskWSys7ONMca43W4za9Ysk5SUZFq3bm1SUlLMtdde6206xhjzwAMPmM6dO5sOHTqYyZMnmz/84Q+NamI7duwwbdu2NS+//LJ33g8//GBSUlLMH/7wB59l165daySZv/zlL6fcbqAaWSD6hjH0juagd9i3d0iqcyosLKxzm7YMQBUVFaZTp04+fyAny87ONpGRkaZbt24mOTnZXHXVVeaLL75ocLtHjx41LpfLO+3Zs4cmdppCvYnddtttVpcR8l544QXTqVOnWkeG6hKIRtZSfcMYeoc/0TvQWLa8C2zVqlU6cOCApkyZUu8yZ599tp577jn97W9/04svviiPx6ORI0eqpIHRQJcsWaKYmBjvlJKS0gLVA+Ht8OHD2rVrl5YuXarp06crKirK6pIktVzfkOgdQDgLqgCUlZWl0aNHKykpqd5lRowYoUmTJmnAgAG6+OKL9frrrys+Pl7Lly+vd5358+fL5XJ5pz179rRE+UBQO/EW2JOnjz766JTrP/TQQ+rdu7cSEhI0f/78AFTcOC3VNyR6ByA1v3cEq6C5DX737t1699139frrrzdpvdatW2vgwIEqKCiod5no6GiepYI6bwO1k23bttX73i9+8YtTrr9o0SItWrTIfwX5QUv2DYnegRr0jm31vteY3hGsgiYAZWdnq0uXLhozZkyT1quurtbnn3+uK664ooUqA8JDrwAMNBlo9A2g5YVj75CC5BSYx+NRdna2Jk+erFatfDPZpEmTfA6333ffffrnP/+pr7/+Wlu2bPGOSzJ16tRAl21r5qeHAAINacm/E/pGaKJ34FQC9TcSFEeA3n33XRUXF+vGG2+s9V5xcbEiThj2/IcfftBNN92ksrIynXHGGRo8eLDWrVunvn37BrJk22rdurWkmgtiT2dUUtjL4cOHJf38d+NP9I3QQu9AY7Vk3ziRw9gwjrvdbsXExMjlcsnpdFpdTsgpLS3VgQMH1KVLF7Vr145HIaAWY4wOHz6svXv3KjY2VomJibWWCcXvYSjWHEzoHWhIoPtGUBwBQmhJSEiQVPPsF6AhsbGx3r8XgN6BxghU3yAAockcDocSExPVpUsXHTt2zOpyEKRat25d73OSYE/0DpxKIPsGAQinLTIykv+DA9Bk9A4Eg6C4CwwAACCQCEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAGqXEXaLcwlyVuEusLgUAmq2V1QUACH5ZW7I0bfU0eYxHEY4IrRi7QpmDMq0uCwBOG0eAADSoxF3iDT+S5DEeTV89nSNBAEIaAQhAg/L35XvDz3HVploF+wssqggAmo8ABKBBaZ3SFOHwbRWRjkj1iutlUUUA0HwEIAANSnYma8XYFYp0REqqCT/Lxy5XsjPZ4soA4PRxETSAU8oclKmMXhkq2F+gXnG9CD8AQh4BCECjJDuTCT4AwganwAAAgO0QgAAAgO0QgAAAgO1YHoAWLVokh8PhM/Xu3bvBdV577TX17t1bbdq00Xnnnac333wzQNUC8CopkXJza/4bYPQNAM1leQCSpHPOOUelpaXe6eOPP6532XXr1mnixInKzMzU1q1bNW7cOI0bN05ffPFFACsGbC4rS0pNlS65pOa/WVkBL4G+AaA5HMYYY2UBixYt0qpVq7Rt27ZGLT9hwgQdOnRIq1ev9s4bPny4BgwYoGeffbZR23C73YqJiZHL5ZLT6TydsgH7KimpCT2eE0aHjoyUioqk5MbfJdac76EVfaO5NQNoPn9+B4PiCFB+fr6SkpLUs2dPXXvttSouLq532fXr12vUqFE+8zIyMrR+/fp616moqJDb7faZAJym/Hzf8CNJ1dVSQWAfjdHSfUOidwDhzPIANGzYMOXk5GjNmjV65plnVFhYqAsvvFA//vhjncuXlZWpa9euPvO6du2qsrKyej9jyZIliomJ8U4pKSl+3QfAVtLSpIiTWkdkpNQrcI/GCETfkOgdQDizPACNHj1aV199tfr166eMjAy9+eabOnDggP7yl7/47TPmz58vl8vlnfbs2eO3bQPhpMRdotzC3Iaf9J6cLK1YURN6pJr/Ll/epNNfzRWIviHRO4BwFnQjQcfGxuqss85SQT2H0xMSElReXu4zr7y8XAkJCfVuMzo6WtHR0X6tEwg3WVuyNG31NHmMRxGOCK0Yu0KZgzLrXjgzU8rIqDnt1atXQMNPXVqib0j0DiCcWX4E6GQHDx7Url27lJiYWOf7I0aM0Nq1a33mvfPOOxoxYkQgygPCUom7xBt+JMljPJq+evqpjwSlp1sefiT6BoCmszwA/f73v9cHH3ygoqIirVu3Tr/+9a8VGRmpiRMnSpImTZqk+fPne5e/7bbbtGbNGj3yyCPauXOnFi1apH/961+aOXOmVbsAhLz8ffne8HNctalWwf7AXtjcWPQNAM1l+SmwkpISTZw4Ufv27VN8fLwuuOACffrpp4qPj5ckFRcXK+KECy5Hjhypl19+Wffcc4/uuusupaWladWqVTr33HOt2gUg5KV1SlOEI8InBEU6ItUrLnAXNjcFfQNAc1k+DpAVGMsDqC1rS5amr56ualOtSEeklo9dXv81QH4Qit/DUKwZCCf+/A5afgQIQHDIHJSpjF4ZKthfoLOPtFdi2cGaQQ+D4BofAPA3y68BAhA8kp3JSl+7S4nnDrf0MRcA0NIIQAB+VlIiTZv280jPHo80fbolDzwFgJZEAALwsyB5zAUAtDQCEICfBcFjLgAgEAhAAH4WBI+5AIBA4C4wAL6C7DEXANASCEAAaktOJvgACGucAgMAALZDAAJspMRdotzC3IYfcgoANsApMMAmsrZkeZ/4HuGI0IqxK1r0URcAEMw4AgTYQIm7RNNWT1PiAY/SC6XEAx5NXz2dI0EAbIsjQIAN5O/L15TNHq34hxRppGqHNO3KahXsL1Cyk4udAdgPR4AAG+h9tIM3/Eg1/13+D+nsI+2tLQxAWAvm6w4JQIANJJYd9Iaf41oZKbH8kDUFAQh7WVuylPp4qi554RKlPp6qrC3B9WBlAhBgBzziAkAAHb/u0GNqni3oMcF33SEBCLADHnEBIIDy9+V7w89x1abmusNgwUXQgF3wiAsAAZLWKU0RjgifEBTpiFSvuOA56swRIMBOkpOl9HTCD4AWlexM1oqxKxTpqDnqHOmI1PKxy4PqrlOOAAEAAL/LHJSpjF4ZKthfoF5xvYIq/EgEIAAA0EKSncm+waekRMrPr7kxw+Ij0ZwCA8JFSYmUm1vzXwAINllZUmqqdMklNf/Nsva2eAIQEA5OaCwmNVX7n1pmdUUA8LOSEmnaNMnz00XRHo80fbqlP9gIQECoO6mxODweOW+9U6+89bDFhQGwg0aN9pyf/3P4Oa66uuauVIsQgIBQV0djaWWkP/9lXlANOgYg/DR6tOcgHIyVAASEurQ0mZMaS5VDyjvDE1SDjgEIL00a7TkIB2MlAAGhLjlZP/zxQVU5al5WOaTpV0plscE16BiA8NLk0Z4zM6WiopqbNYqKal5biNvggTAQN/P3euVMoz//ZZ7yzvCoLDb4Bh0DEF5Oa7Tn5GTLb38/jgAEhImJo+/Uhf8xMWgHHQMQXo6P9jx99XRVm+qgHO25IQQgIIzUGnQMAFrQiaM9n32kvRLLDtbcmRokR3kawjVAAADgtCU7k5W+dpcSzx0eNIMcNgYBCAgFjPIMIFgF4SCHjUEAAoJdkA0fDwA+gnCQw8YgAAHBLER/WQEIH6cc6TkIBzlsDAIQEMxC9JcVgPDQqJGeg3CQw8YgAAHBrI5fViYEflkBCH1NGuk5yAY5bAzLA9CSJUt0/vnnq2PHjurSpYvGjRunvLy8BtfJycmRw+Hwmdq0aROgioEA+umXleenEFTlkKaN8Shr79sWF2Yt+gbQ8po80nNyspSeHvRHfo6zfBygDz74QDNmzND555+vqqoq3XXXXbrsssu0fft2tW/fvt71nE6nT8NzOByBKBcIuJKrMzRyu1HPfVJBnPRNjFH26unK6JVh2zF/6BtAyzutkZ5DiOUBaM2aNT6vc3Jy1KVLF23evFkXXXRRves5HA4lJCQ06jMqKipUUVHhfe12u0+vWMAC+fvytcdptMf587zjv8LsGoAC0Tckegfs7cSRnhMOVKv3DxHK/K8lYdN3LD8FdjKXyyVJiouLa3C5gwcPKjU1VSkpKfrVr36lL7/8st5llyxZopiYGO+UkpLi15qBlnT8V9iJwulXmD+0RN+Q6B1A5qBM7Y1bqj1/jNC7OR5NHDsvbIbicBhjjNVFHOfxeHTVVVfpwIED+vjjj+tdbv369crPz1e/fv3kcrm0bNkyffjhh/ryyy+VXMe5x7p+xaWkpMjlcsnpdNZaHgg2WVuyaj1vJ3NQ8F9k2BC3262YmJhmfw9bqm9I9A5AJSU144+deDdqZGTNhc4WXOvjr74hBVkAuuWWW/TWW2/p448/rrch1eXYsWPq06ePJk6cqPvvv/+Uy/vzf0CgWUpKam51T0s7ZTMpcZeE1YNO/fU9DFTfkOgdsKHc3JpBWOuan54e8HL8+R0MmlNgM2fO1OrVq5Wbm9ukJiZJrVu31sCBA1XA2CgIJU0c4TnZmaz07ulhEX78hb4BNF+DAx2G6CCHjWF5ADLGaObMmXrjjTf03nvvqUePHk3eRnV1tT7//HMlJia2QIVAC2CE52ahbwD+ccqBDkN0kMPGsDwAzZgxQy+++KJefvlldezYUWVlZSorK9ORI0e8y0yaNEnz58/3vr7vvvv0z3/+U19//bW2bNmi6667Trt379bUqVOt2AWg6RjhuVnoG0DzNXqgwxAc5LAxLL8N/plnnpEkpZ90LjE7O1tTpkyRJBUXFyvihENwP/zwg2666SaVlZXpjDPO0ODBg7Vu3Tr17ds3UGUDzXP8sPLJFxaGwWHlQKBvAM3X0ECHtU61JyeHxVGfEwXVRdCBwoWMCApZWTWnvaqrZSIjlfffd6jD726zzTU+ofg9DMWagfqUuEuU+nhqrYEOi24vCto+FJYXQQO289Nh5f9b/nul3uZRn4pl9T9sEAD87PhAh93cEUovlLq5I7R87PKgDT/+ZvkpMMDOSpzSVWWPyuOsORB7/By8nR9zASBwMrdKNz4uOTySiZAcfSUNsrqqwOAIEGChJj9sEAD85ae7UR0/XYvosNndqAQgoCWUlNTcMXGKRsJjLgBYxuZ3oxKAAH9rwgCHx8/BRzpqxtg4/pgLTn8BaHFhPMhhY3AXGHdywJ9O87k54faYi8YIxe9hKNYMeytxlyh/X77SOqXV3VtOuBvVO8hhEI/z48/vIBdBA/7U0CHlBgJQsjPZNsEHQGBkbcnyDnQY4YjQirEraj9EOTNTysio6VG9eoXdWD8N4RQY4E82P6QMIDg0epRnqSb0pKfbKvxIBCDAv8L4uTkAQgd3mJ4ap8AAfzvhkHJp1/ba2eag0twlnOICEDBpndKU4nbozH1G+XHSNzHcYXoyAhDQEpKTlbX3bU177RTn3wGgBSS/9raKHpciPFK1Q7r5SoeGL+QO0xNxCgxoikaO79Ok8+8A4E8/DXAY4am5yTvSSCv+L0KZXTIsLiy4EICAxmrC+D6cfwdgmTruRnXYaIDDxiIAAY3x0y8qb1M5xZDxjPAMwDLcjdooBCCgMZo4ZDwjPANoaSXuEuUW5tY+tc7dqI3CRdBAYxz/RXXyCM8N/KLKHJSpjF4ZthvhGUDLO+UghzYe4LCxOAIENMZp/qJKdiYrvXs64QeA3zT6JgubDnDYWAQgoLEyM2ue6ZWbq9LP1yv3kp7c1QUg4Iq/WKeLvvboF66f53GTRdMRgICmSE5WlnOXkl8brkteuESpj6cqa0v9d4MBgF9lZWnEhROV+7y0+3Hpxi01s7nJoukIQEATML4PAMv8dDeq46drESONtPwfUjd3BDdZnAYuggakmsaSn19zsXMD58sbGt+H5gOgRdVxN2orI/3rklcVP+hqi4oKXRwBApowwCHj+wCwTD3j+8T3H2FNPSGOAAR7a+IAh4zvA8AyjO/jV5wCg701NMBhPU2F8X0AtLQSd4ny9+UrrVOab49hfB+/IQDB3k5jgEOp5kgQwQdASzjlIIfJyQQfP+AUGOztpEPKJjJC+x9fSnMBYAnuNA0cAhCQmalX/rFEl0xxKOVWj+L3z2VsHwCWYJDDwCEAwfZK3CW6btM85XY3+iaGX1wALMIghwFFAEJ4KymRcnPrvatLanhsHwAICAY5DDgCEMJXI8f3YWwfAJZrYJBDnwug4TcEIISnJozvw9g+ACzHIIcBx23wCE9NHN+HsX0AWOr4HanTp9f0KgY5bHEEIISnOsb3qXJIrx3ZpIlKr3MVxvYBYCkGOQwoToEhPCUna/8fH1SVo+ZllUOafqV0/ab53N0FwBIl7hLlFuY23IOSk6X0dMJPAHAECGHrszGDdf3XUq/9UkGc9E2MJJ7cDsACpxzdGQEXFEeAnn76aXXv3l1t2rTRsGHDtHHjxgaXf+2119S7d2+1adNG5513nt58880AVYpQktYpTaWxEfqgx0/hR9zdFW7oHQgFJe4SLX7pJu8Ah4w1FhwsD0ArV67U7NmztXDhQm3ZskX9+/dXRkaG9u7dW+fy69at08SJE5WZmamtW7dq3LhxGjdunL744osAV45gx91d4Y3egVBx8E9/VOFjxmeAQ8Yas57DGGOsLGDYsGE6//zz9dRTT0mSPB6PUlJSNGvWLM2bN6/W8hMmTNChQ4e0evVq77zhw4drwIABevbZZ+v8jIqKClVUVHhfu91upaSkyOVyyel0+nmPEGxK3CXc3RWE3G63YmJiTvt7SO9ASCgpkUlN9Q5wKNVck3jmHRH6ZOFuelITNbdvnMjSI0CVlZXavHmzRo0a5Z0XERGhUaNGaf369XWus379ep/lJSkjI6Pe5SVpyZIliomJ8U4pKSn+2QGEhGRnstK7p9Nowgi9AyEjP98n/Eg1Axz+6ezZ9CSLWRqAvv/+e1VXV6tr164+87t27aqysrI61ykrK2vS8pI0f/58uVwu77Rnz57mFw/AMvQOhIw6Bjg0kZEac8VtFhWE42xxF1h0dLSio6OtLgNAiKF3oNnqGODQwQCHQcHSANS5c2dFRkaqvLzcZ355ebkSEhLqXCchIaFJywMIP/QOhBQGOAxKlp4Ci4qK0uDBg7V27VrvPI/Ho7Vr12rEiLqffzJixAif5SXpnXfeqXd5AOGH3oFgwgCHIcpY7NVXXzXR0dEmJyfHbN++3UybNs3ExsaasrIyY4wx119/vZk3b553+U8++cS0atXKLFu2zOzYscMsXLjQtG7d2nz++eeN/kyXy2UkGZfL5ff9AdA4zf0e0jsQDP68+c8mYnGE0SKZiMUR5s+b/2x1SWHNn99By68BmjBhgr777jvde++9Kisr04ABA7RmzRrvxYrFxcWKOOECspEjR+rll1/WPffco7vuuktpaWlatWqVzj33XKt2AYAF6B2wmneAw31G+XHSNzE1Axxm9MrgDq8QYPk4QFbw5zgCAE5PKH4PQ7FmtJydS+9U2l3LFGmkaoc07UrpuUFS7uRcpXdPt7q8sBQ24wABABCSSkp09t2PKvKnQwiRRlr+D6mbO4LH7YQIAhAAAE3FAIchjwAEAEBTMcBhyCMAAQDQVMcHOIysedgyAxyGHsvvAgMAICQxwGFIIwABAHCSEneJ8vflK61TWsPX9CQnE3xCFAEIAIATZG3J0rTV0+QxHkU4IrRi7AplDsq0uiz4GdcAAQDwE+/ghl979AuX5DE1gxs2+JgLhCSOAAEA8JODf/qjCh8zJw1uWK2C/QXc3h5mOAIEAIDE4IY2QwACAEBicEObIQABACAxuKHNEIAAAJAY3NBmuAgaAIDjGNzQNghAAACciMENbYFTYAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYsC0BFRUXKzMxUjx491LZtW5155plauHChKisrG1wvPT1dDofDZ7r55psDVDUAq9E7APhDK6s+eOfOnfJ4PFq+fLl69eqlL774QjfddJMOHTqkZcuWNbjuTTfdpPvuu8/7ul27di1dLoAgQe8A4A+WBaDLL79cl19+ufd1z549lZeXp2eeeeaUTaxdu3ZKSEho6RIBBCF6BwB/CKprgFwul+Li4k653EsvvaTOnTvr3HPP1fz583X48OEGl6+oqJDb7faZAIQPegeAprLsCNDJCgoK9OSTT57yF9w111yj1NRUJSUl6d///rfmzp2rvLw8vf766/Wus2TJEi1evNjfJQMIAvQOAKfF+NncuXONpAanHTt2+KxTUlJizjzzTJOZmdnkz1u7dq2RZAoKCupd5ujRo8blcnmnPXv2GEnG5XI1+fMA+IfL5fL5HtI7AJzKyX2jORzGGOPPQPXdd99p3759DS7Ts2dPRUVFSZK+/fZbpaena/jw4crJyVFERNPOyh06dEgdOnTQmjVrlJGR0ah13G63YmJi5HK55HQ6m/R5APzj5O8hvQPAqfjzO+j3U2Dx8fGKj49v1LLffPONfvnLX2rw4MHKzs5ucgOTpG3btkmSEhMTm7wugOBB7wAQSJZdBP3NN98oPT1d3bp107Jly/Tdd9+prKxMZWVlPsv07t1bGzdulCTt2rVL999/vzZv3qyioiL9/e9/16RJk3TRRRepX79+Vu0KgACidwDwB8sugn7nnXdUUFCggoICJScn+7x3/KzcsWPHlJeX571TIyoqSu+++64ef/xxHTp0SCkpKRo/frzuueeegNcPwBr0DgD+4PdrgEIB5/EB64Xi9zAUawbCiT+/g0E1DhAAAEAgEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtWBqAunfvLofD4TMtXbq0wXWOHj2qGTNmqFOnTurQoYPGjx+v8vLyAFUMIBjQOwA0l+VHgO677z6VlpZ6p1mzZjW4/B133KF//OMfeu211/TBBx/o22+/1W9+85sAVQsgWNA7ADRHK6sL6NixoxISEhq1rMvlUlZWll5++WVdcsklkqTs7Gz16dNHn376qYYPH96SpQIIIvQOAM1h+RGgpUuXqlOnTho4cKAefvhhVVVV1bvs5s2bdezYMY0aNco7r3fv3urWrZvWr19f73oVFRVyu90+E4DQRu8A0ByWHgG69dZbNWjQIMXFxWndunWaP3++SktL9eijj9a5fFlZmaKiohQbG+szv2vXriorK6v3c5YsWaLFixf7s3QAFqJ3AGguvx8BmjdvXq2LE0+edu7cKUmaPXu20tPT1a9fP91888165JFH9OSTT6qiosKvNc2fP18ul8s77dmzx6/bB9B89A4AgeT3I0Bz5szRlClTGlymZ8+edc4fNmyYqqqqVFRUpLPPPrvW+wkJCaqsrNSBAwd8fsmVl5c3eC1AdHS0oqOjG1U/AGvQOwAEkt8DUHx8vOLj409r3W3btikiIkJdunSp8/3BgwerdevWWrt2rcaPHy9JysvLU3FxsUaMGHHaNQOwHr0DQCBZdg3Q+vXrtWHDBv3yl79Ux44dtX79et1xxx267rrrdMYZZ0iSvvnmG1166aV64YUXNHToUMXExCgzM1OzZ89WXFycnE6nZs2apREjRnAXB2AT9A4A/mBZAIqOjtarr76qRYsWqaKiQj169NAdd9yh2bNne5c5duyY8vLydPjwYe+8xx57TBERERo/frwqKiqUkZGhP/3pT1bsAgAL0DsA+IPDGGOsLiLQ3G63YmJi5HK55HQ6rS4HsKVQ/B6GYs1AOPHnd9DycYAAAAACjQAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABshwAEAABsx7IA9P7778vhcNQ5bdq0qd710tPTay1/8803B7ByAFaidwDwh1ZWffDIkSNVWlrqM2/BggVau3athgwZ0uC6N910k+677z7v63bt2rVIjQCCD70DgD9YFoCioqKUkJDgfX3s2DH97W9/06xZs+RwOBpct127dj7rArAPegcAfwiaa4D+/ve/a9++fbrhhhtOuexLL72kzp0769xzz9X8+fN1+PDhBpevqKiQ2+32mQCEB3oHgNNh2RGgk2VlZSkjI0PJyckNLnfNNdcoNTVVSUlJ+ve//625c+cqLy9Pr7/+er3rLFmyRIsXL/Z3yQCCAL0DwGkxfjZ37lwjqcFpx44dPuvs2bPHREREmL/+9a9N/ry1a9caSaagoKDeZY4ePWpcLpd32rNnj5FkXC5Xkz8PgH+4XC6f7yG9A8CpnNw3msPvR4DmzJmjKVOmNLhMz549fV5nZ2erU6dOuuqqq5r8ecOGDZMkFRQU6Mwzz6xzmejoaEVHRzd52wACh94BIJD8HoDi4+MVHx/f6OWNMcrOztakSZPUunXrJn/etm3bJEmJiYlNXhdA8KB3AAgkyy+Cfu+991RYWKipU6fWeu+bb75R7969tXHjRknSrl27dP/992vz5s0qKirS3//+d02aNEkXXXSR+vXrF+jSAViI3gGgOSy/CDorK0sjR45U7969a7137Ngx5eXlee/UiIqK0rvvvqvHH39chw4dUkpKisaPH6977rkn0GUDsBi9A0BzOIwxxuoiAs3tdismJkYul0tOp9PqcgBbCsXvYSjWDIQTf34HLT8FBgAAEGgEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDsEIAAAYDstFoAeeOABjRw5Uu3atVNsbGydyxQXF2vMmDFq166dunTpojvvvFNVVVUNbnf//v269tpr5XQ6FRsbq8zMTB08eLAF9gCAFegdAAKhxQJQZWWlrr76at1yyy11vl9dXa0xY8aosrJS69at0/PPP6+cnBzde++9DW732muv1Zdffql33nlHq1ev1ocffqhp06a1xC4AsAC9A0AgOIwxpiU/ICcnR7fffrsOHDjgM/+tt97S2LFj9e2336pr166SpGeffVZz587Vd999p6ioqFrb2rFjh/r27atNmzZpyJAhkqQ1a9boiiuuUElJiZKSkuqsoaKiQhUVFd7XLpdL3bp10549e+R0Ov20pwCawu12KyUlRQcOHFBMTEyt9+kdAE52qr7RJKaFZWdnm5iYmFrzFyxYYPr37+8z7+uvvzaSzJYtW+rcVlZWlomNjfWZd+zYMRMZGWlef/31emtYuHChkcTExBSE065du+gdTExMTZrq6xtN0UoWKSsr8/56O+7467KysnrX6dKli8+8Vq1aKS4urt51JGn+/PmaPXu29/WBAweUmpqq4uLi5ifIIHQ8IYfzr9Rw38dw3z/p56MpcXFxTVqP3tFywv3vLtz3Twr/fTzdvlGXJgWgefPm6cEHH2xwmR07dqh3797NKsrfoqOjFR0dXWt+TExMWP6BHOd0OsN6/6Tw38dw2b+GescZZ5whid4RTMLl764+4b5/UvjvY0RE8y9hblIAmjNnjqZMmdLgMj179mzUthISErRx40afeeXl5d736ltn7969PvOqqqq0f//+etcBYL26esfBgwd1/vnna9OmTerQoQO9A0BANSkAxcfHKz4+3i8fPGLECD3wwAPau3ev99D0O++8I6fTqb59+9a7zoEDB7R582YNHjxYkvTee+/J4/Fo2LBhfqkLgP/V1Tvcbrck6ayzzmrSL1V6BwB/aLHb4IuLi7Vt2zYVFxerurpa27Zt07Zt27zjblx22WXq27evrr/+en322Wd6++23dc8992jGjBneQ84bN25U79699c0330iS+vTpo8svv1w33XSTNm7cqE8++UQzZ87Ub3/723rv4qhLdHS0Fi5cWOeh7XAQ7vsnhf8+hvv+SfXvI73DOuxf6Av3ffTr/jX7Mup6TJ48uc4rt3Nzc73LFBUVmdGjR5u2bduazp07mzlz5phjx45538/NzTWSTGFhoXfevn37zMSJE02HDh2M0+k0N9xwg/nxxx9bajcABBi9A0AgtPg4QAAAAMGGZ4EBAADbIQABAADbIQABAADbIQABAADbsV0AeuCBBzRy5Ei1a9dOsbGxdS5TXFysMWPGqF27durSpYvuvPNOVVVVBbZQP+revbscDofPtHTpUqvLOm1PP/20unfvrjZt2mjYsGG1BsULZYsWLar1bxVsoyM3xYcffqgrr7xSSUlJcjgcWrVqlc/7xhjde++9SkxMVNu2bTVq1Cjl5+dbU2wD6Buh3zek8O0d4dY3pMD0DtsFoMrKSl199dW65ZZb6ny/urpaY8aMUWVlpdatW6fnn39eOTk5uvfeewNcqX/dd999Ki0t9U6zZs2yuqTTsnLlSs2ePVsLFy7Uli1b1L9/f2VkZNQa5TeUnXPOOT7/Vh9//LHVJZ22Q4cOqX///nr66afrfP+hhx7SE088oWeffVYbNmxQ+/btlZGRoaNHjwa40obRN0K7b0jh3zvCqW9IAeod1t6Fb536njT95ptvmoiICFNWVuad98wzzxin02kqKioCWKH/pKammscee8zqMvxi6NChZsaMGd7X1dXVJikpySxZssTCqvxn4cKFtZ50Hi4kmTfeeMP72uPxmISEBPPwww975x04cMBER0ebV155xYIKT42+EbrCuXeEc98wpuV6h+2OAJ3K+vXrdd555/k8bTojI0Nut1tffvmlhZU1z9KlS9WpUycNHDhQDz/8cEgemq+srNTmzZs1atQo77yIiAiNGjVK69evt7Ay/8rPz1dSUpJ69uypa6+9VsXFxVaX1CIKCwtVVlbm8+8ZExOjYcOGhdy/J30juNmhd9ilb0j+6x1NehaYHZSVlfk0MUne12VlZVaU1Gy33nqrBg0apLi4OK1bt07z589XaWmpHn30UatLa5Lvv/9e1dXVdf777Ny506Kq/GvYsGHKycnR2WefrdLSUi1evFgXXnihvvjiC3Xs2NHq8vzq+Peprn/PUPuu0TeCW7j3Djv1Dcl/vSMsjgDNmzev1gVgJ0/h8Ed+oqbs8+zZs5Wenq5+/frp5ptv1iOPPKInn3xSFRUVFu8FTjZ69GhdffXV6tevnzIyMvTmm2/qwIED+stf/mJ1aWGHvkHfCBf0jdMTFkeA5syZoylTpjS4TM+ePRu1rYSEhFp3BpSXl3vfCxbN2edhw4apqqpKRUVFOvvss1ugupbRuXNnRUZGev89jisvLw+qfxt/io2N1VlnnaWCggKrS/G74/9m5eXlSkxM9M4vLy/XgAEDWvzz6Rt1C7e+Idmvd4Rz35D81zvCIgDFx8crPj7eL9saMWKEHnjgAe3du1ddunSRJL3zzjtyOp3q27evXz7DH5qzz9u2bVNERIR3/0JFVFSUBg8erLVr12rcuHGSJI/Ho7Vr12rmzJnWFtdCDh48qF27dun666+3uhS/69GjhxISErR27Vpv03K73dqwYUO9d1v5E32jaUK1b0j26x3h3DckP/YOf16pHQp2795ttm7dahYvXmw6dOhgtm7darZu3ep9KnRVVZU599xzzWWXXWa2bdtm1qxZY+Lj4838+fMtrvz0rFu3zjz22GNm27ZtZteuXebFF1808fHxZtKkSVaXdlpeffVVEx0dbXJycsz27dvNtGnTTGxsrM/dN6Fszpw55v333zeFhYXmk08+MaNGjTKdO3c2e/futbq00/Ljjz96v2OSzKOPPmq2bt1qdu/ebYwxZunSpSY2Ntb87W9/M//+97/Nr371K9OjRw9z5MgRiyv3Rd8I7b5hTHj3jnDrG8YEpnfYLgBNnjzZSKo15ebmepcpKioyo0ePNm3btjWdO3c2c+bMMceOHbOu6GbYvHmzGTZsmImJiTFt2rQxffr0Mf/zP/9jjh49anVpp+3JJ5803bp1M1FRUWbo0KHm008/tbokv5kwYYJJTEw0UVFR5he/+IWZMGGCKSgosLqs05abm1vn923y5MnGmJrbWRcsWGC6du1qoqOjzaWXXmry8vKsLboO9I3Q7xvGhG/vCLe+YUxgeofDGGOaezgKAAAglITFXWAAAABNQQACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC28/8BuaZaCO5o8SMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = sorted_combined[-19]\n",
    "plotPoints(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
