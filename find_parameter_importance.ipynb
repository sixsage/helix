{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sixsa\\anaconda3\\envs\\helix\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 172\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "PATH = \"tracks_100k_updated.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "i want to\n",
    "get some parameters - plot the actual points using those parameters\n",
    "then i can rescale those parameters, add some noise, restore the scale, and then plot again\n",
    "calculate the distance\n",
    "'''\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r') as file:\n",
    "            content = file.read()\n",
    "            data_points = content.split('EOT')\n",
    "\n",
    "            data_points = [dp.strip() for dp in data_points if dp.strip()]\n",
    "            data_points = [dp.split('\\n') for dp in data_points]\n",
    "            data_points = [[[float(cell) for cell in row.split(', ')] for row in dp] for dp in data_points]\n",
    "            self.original_targets = np.array([dp[0] for dp in data_points])\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.rescaled_targets = self.scaler.fit_transform(self.original_targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rescaled_targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original = self.original_targets[idx]\n",
    "        rescaled = self.rescaled_targets[idx]\n",
    "        return original, rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.5000e-03, 3.1300e+00, 1.5818e+02, 5.0000e-02, 3.7000e-01]),\n",
       " array([0.16634051, 0.49840764, 0.76101492, 0.47786606, 0.62909091]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.   25.01 -4.16 -1.36]\n",
      "[5.11e-02 6.28e+00 2.00e+02 4.65e+00 1.39e+00]\n",
      "[5.1100e-02 6.2800e+00 1.7499e+02 8.8100e+00 2.7500e+00]\n"
     ]
    }
   ],
   "source": [
    "original_mins = np.min(d.original_targets, axis=0)\n",
    "original_maxs = np.max(d.original_targets, axis=0)\n",
    "print(original_mins)\n",
    "print(original_maxs)\n",
    "print(original_maxs - original_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "rescaled_mins = np.min(d.rescaled_targets, axis=0)\n",
    "rescaled_maxs = np.max(d.rescaled_targets, axis=0)\n",
    "print(rescaled_mins)\n",
    "print(rescaled_maxs)\n",
    "print(rescaled_maxs - rescaled_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_r0=1.0\n",
    "max_r0=10.0\n",
    "nlayers=10\n",
    "sigma=0.01\n",
    "\n",
    "def track(phi, d0,phi0,pt,dz,tanl):\n",
    "    alpha = 1/2 # 1/cB\n",
    "    q=1\n",
    "    kappa = q/pt\n",
    "    rho = alpha/kappa\n",
    "    x = d0*np.cos(phi0) + rho*(np.cos(phi0)-np.cos(phi0+phi))\n",
    "    y = d0*np.sin(phi0) + rho*(np.sin(phi0)-np.sin(phi0+phi))\n",
    "    z = dz - rho*tanl*phi\n",
    "    return x,y,z\n",
    "\n",
    "def dr(phi, r02,d0,phi0,pt,dz,tanl):\n",
    "\n",
    "    # get the xyz of the track at this phi\n",
    "    x,y,z = track(phi, d0,phi0,pt,dz,tanl)\n",
    "    r2=x*x+y*y\n",
    "\n",
    "    # get the distance from the target r02\n",
    "    dr = np.fabs(r2-r02)\n",
    "\n",
    "    return dr\n",
    "\n",
    "def find_phi(r0, d0,phi0,pt,dz,tanl):\n",
    "\n",
    "    # this is lazy, but rather than inverting the equations we just minimize the distance\n",
    "    res = scipy.optimize.minimize(dr,0,method='Nelder-Mead',args = (r0, d0,phi0,pt,dz,tanl))#, bounds =(0,1.0))\n",
    "\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "# find the intersections with the detector layers for these track parameters, add noise\n",
    "def make_hits(params):\n",
    "    xs=[]\n",
    "    ys=[]\n",
    "    zs =[]\n",
    "    \n",
    "    for r0 in np.linspace(min_r0,max_r0,nlayers):\n",
    "        phi0 = find_phi(r0*r0,*params)\n",
    "        x0,y0,z0 = track(phi0,*params)\n",
    "        xs.append(x0)\n",
    "        ys.append(y0)\n",
    "        zs.append(z0)\n",
    "\n",
    "\n",
    "    return xs,ys,zs\n",
    "\n",
    "def chisq(params,x,y,z):\n",
    "    ihit=0\n",
    "    c2=0\n",
    "\n",
    "    # find the hits for the track parameters\n",
    "    for r0 in np.linspace(min_r0,max_r0,nlayers):\n",
    "        phi0 = find_phi(r0*r0,*params)\n",
    "        x0,y0,z0 = track(phi0,*params)\n",
    "        # calculate deviation from observed hit\n",
    "        c2 = c2 + (x0-x[ihit])**2 + (y0-y[ihit])**2 + (z0-z[ihit])**2   # assume equal uncertainty in x,y,z\n",
    "        ihit = ihit+1\n",
    "\n",
    "    return c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chisq_distance(original_parameters, changed_parameters):\n",
    "    changed_x, changed_y, changed_z = make_hits(changed_parameters)\n",
    "    return chisq(original_parameters, changed_x, changed_y, changed_z)\n",
    "\n",
    "def test_parameter_importance(index, dataset: Dataset, noise=0.01):\n",
    "    '''\n",
    "    get original parameter\n",
    "    minmax scale it\n",
    "    for each parameter, add noise\n",
    "    inverse the noise\n",
    "    calculate the chisq distance\n",
    "    rank based on importance\n",
    "    '''\n",
    "    original_parameters, rescaled_parameters = dataset[index]\n",
    "    parameter_names = ['d0','phi0','pt','dz','tanl']\n",
    "    distances = []\n",
    "    for i in range(len(parameter_names)):\n",
    "        temp = rescaled_parameters.copy()\n",
    "        temp[i] += noise\n",
    "        if temp[i] > 1:\n",
    "            raise ValueError('out of bound')\n",
    "        scale_restored_temp = dataset.scaler.inverse_transform([temp])[0]\n",
    "        distance = calculate_chisq_distance(original_parameters, scale_restored_temp)\n",
    "        distances.append(distance)\n",
    "    return sorted(zip(distances, parameter_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.000e-03,  1.080e+00,  5.175e+01, -2.130e+00,  1.700e-01]),\n",
       " array([0.07827789, 0.17197452, 0.15280873, 0.23041998, 0.55636364]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(146.91319778402934, 'phi0'),\n",
       " (29.35336308583485, 'tanl'),\n",
       " (7.761610000000012, 'dz'),\n",
       " (0.6176208585327747, 'pt'),\n",
       " (0.00025021688112549347, 'd0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameter_importance(INDEX, d, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for i in range(len(d)):\n",
    "    try:\n",
    "        result = test_parameter_importance(i, d, 0.1)\n",
    "    except:\n",
    "        continue\n",
    "    ordering = tuple(element[1] for element in result)\n",
    "    counter[ordering] += 1\n",
    "    if i > 2000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('phi0', 'tanl', 'dz', 'pt', 'd0'): 1619})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
